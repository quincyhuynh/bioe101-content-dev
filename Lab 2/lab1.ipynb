{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BioE 101 Lab 1 - Analyzing Frequency Spectrums#\n",
    "\n",
    "## Objectives: ##\n",
    "\n",
    "- Learn how to program with Python (or at least become more familiar with Python)\n",
    "\n",
    "- Use Python to see your voice with your computer's microphone in the time and frequency domain\n",
    "\n",
    "- Use an Arduino with a function generator to sample waveforms\n",
    "\n",
    "- Observe aliasing and quantization error in sampled data\n",
    "\n",
    "- Estimate noise and SNR from sampled data\n",
    "\n",
    "- (Bonus) Build an algorithm with Python to distinguish you and your partnerâ€™s voice or build a digital filter for noisy data\n",
    "\n",
    "There will be two weeks for this lab. Each group will have to turn in a lab report with the answers to all the questions below. There are 7 questions with 2 bonus questions. For the bonus questions, you must turn in your code as well to show proof of an attempt.\n",
    "\n",
    "#### Before starting the lab:  \n",
    "Download everything in the Lab 1 Folder on bCourses > Files > Lab 1 to the same folder as your lab1 notebook file\n",
    "\n",
    "#### Lab Report Submission:\n",
    "Write down the answers in the notebook or a Word Doc. Everyone in the group each needs to turn in the lab report. Make sure to include all your names and student IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Displaying signals in time and frequency domain with Python\n",
    "\n",
    "We're going to generate waveform inputs into the Arduino and view it in the time and frequency domains. The Arduino has a 10-bit ADC built into it. That puts a limit on how small our input can be. ADCs take in an analog voltage and outputs a \"code\" that goes from $0$ to $2^{B}$ where $B$ is the number of bits. In the Arduino's case, that means that the ADCs will read in a voltage that goes from 0V to 3.3V and map that to $0$ to $1023$.\n",
    "\n",
    "**Question 1**: If our ADC is 10 bits, what is the smallest voltage difference we can observe between any two points?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn to plot a function and its spectrum in Python ###\n",
    "Run the cell below to import some necessary libraries. Numpy is used for scientific-computing (i.e., lots of linear algebra and DSP). Matplotlib is a plotting library very similar to how matplot makes its plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # import numpy to create functions\n",
    "import matplotlib.pyplot as plt # import the plotting library\n",
    "from scipy.fftpack import fft # fft function from scipy\n",
    "# set matplotlib to plot the graphs inside the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to generate a sine wave and plot its Fourier Transform. Feel free to play around with the values! A little run-down of what's going on:\n",
    "- np.arange(n) creates an a n-size array going from 0 to n-1\n",
    "- np.sin(x) creates an array that evaluates sin at every value in the array of x\n",
    "- plt.plot(x,y) plots y with respect to x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_ft_sinewave(sample_freq, freq):\n",
    "    Fs = sample_freq;  # sampling rate\n",
    "    Ts = 1.0/Fs; # sampling interval\n",
    "    t = np.arange(0,Ts*500,Ts) # time vector - sample duration of 1 sec\n",
    "\n",
    "    ff = freq;   # frequency of the signal\n",
    "    y = np.sin(2*np.pi*ff*t)\n",
    "\n",
    "    n = len(y) # length of the signal\n",
    "    k = np.arange(n)\n",
    "    T = n/Fs\n",
    "    frq = k/T # two sides frequency range\n",
    "    frq = frq[range(n//2)] # one side frequency range\n",
    "\n",
    "    Y = fft(y)/n # fft computing and normalization\n",
    "    Y = Y[range(n//2)]\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1,figsize=(20,10))\n",
    "    ax[0].plot(t,y)\n",
    "    ax[0].set_xlabel('Time')\n",
    "    ax[0].set_ylabel('Amplitude')\n",
    "    ax[1].plot(frq,abs(Y),'r') # plotting the spectrum\n",
    "    ax[1].set_xlabel('Freq (Hz)')\n",
    "    ax[1].set_ylabel('|Y(freq)|')\n",
    "    plt.show()\n",
    "\n",
    "plot_ft_sinewave(1000, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**: Let's play around with some values. Plot a 1 kHz sine wave sampled at 3k samples/second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_ft_sinewave(*,*) # replace * with the appropriate sampling frequency and sine wave frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**: Plot a 400 Hz sine wave sampled at 1k samples/second and plot a 600 Hz sine wave sampled at 1k samples/second. What do you notice, and why is this happening? What would you change about how these signals were acquired to prevent this phenomenon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot 400 Hz\n",
    "plot_ft_sinewave(*,*) # replace * with the appropriate sampling frequency and sine wave frequency\n",
    "# Plot 600 Hz\n",
    "plot_ft_sinewave(*,*) # replace * with the appropriate sampling frequency and sine wave frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Observe audio signals in time and frequency domains using your microphone.\n",
    "\n",
    "Now that we've successfully used our time domain and frequency domain analysis tools on python generated signals, let's actually use real world signals. For audio signals in particular, frequency analysis tools are pretty useful.\n",
    "\n",
    "Make sure someone in your group has a computer with a microphone built-in and PyAudio installed.\n",
    "\n",
    "If running the cell below gives an error related to matplotlib or tk, then in your terminal run these commands:  \n",
    "$\\texttt{conda update matplotlib}$  \n",
    "$\\texttt{conda update ipython}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyaudio\n",
    "import struct\n",
    "from scipy.fftpack import fft\n",
    "import sys\n",
    "import time\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio Spectrum Analyzer\n",
    "Below is a class object that uses your microphone to plot your voice in time and in the frequency domain. Run the cell to define the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AudioStream(object):\n",
    "    def __init__(self):\n",
    "\n",
    "        # stream constants\n",
    "        self.CHUNK = 1024 * 20 # play around with this value for Question 4, keep as multiple of 1024\n",
    "        self.FORMAT = pyaudio.paInt16\n",
    "        self.CHANNELS = 1\n",
    "        self.RATE = 44100\n",
    "        self.pause = False\n",
    "\n",
    "        # stream object\n",
    "        self.p = pyaudio.PyAudio()\n",
    "        self.stream = self.p.open(\n",
    "            format=self.FORMAT,\n",
    "            channels=self.CHANNELS,\n",
    "            rate=self.RATE,\n",
    "            input=True,\n",
    "            output=True,\n",
    "            frames_per_buffer=self.CHUNK,\n",
    "        )\n",
    "        self.init_plots()\n",
    "        self.start_plot()\n",
    "\n",
    "    def init_plots(self):\n",
    "\n",
    "        # x variables for plotting\n",
    "        x = np.arange(0, 2 * self.CHUNK, 2)\n",
    "        xf = np.linspace(0, self.RATE, self.CHUNK)\n",
    "\n",
    "        # create matplotlib figure and axes\n",
    "        self.fig, (ax1, ax2) = plt.subplots(2, figsize=(15, 7))\n",
    "        self.fig.canvas.mpl_connect('button_press_event', self.onClick)\n",
    "\n",
    "        # create a line object with random data\n",
    "        self.line, = ax1.plot(x, np.random.rand(self.CHUNK), '-', lw=2)\n",
    "\n",
    "        # create line for spectrum\n",
    "        self.line_fft, = ax2.plot(\n",
    "            xf, np.random.rand(self.CHUNK), '-', lw=2)\n",
    "\n",
    "        # format waveform axes\n",
    "        ax1.set_title('AUDIO WAVEFORM')\n",
    "        ax1.set_xlabel('samples')\n",
    "        ax1.set_ylabel('volume')\n",
    "        ax1.set_ylim(-50, 300)\n",
    "        ax1.set_xlim(0, 2 * self.CHUNK)\n",
    "        plt.setp(\n",
    "            ax1, yticks=[0, 128, 255],\n",
    "            xticks=[0, self.CHUNK, 2 * self.CHUNK],\n",
    "        )\n",
    "        plt.setp(ax2, yticks=[-100, -50, 0],)\n",
    "\n",
    "        # format spectrum axes\n",
    "        ax2.set_xlim(20, 2000)\n",
    "\n",
    "        # show axes\n",
    "        thismanager = plt.get_current_fig_manager()\n",
    "        # thismanager.window.setGeometry(5, 120, 1910, 1070)\n",
    "        plt.show(block=False)\n",
    "\n",
    "    def start_plot(self):\n",
    "\n",
    "        print('stream started')\n",
    "        frame_count = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        try:\n",
    "            while not self.pause:\n",
    "                data = self.stream.read(self.CHUNK, exception_on_overflow=False)\n",
    "                data_int = struct.unpack(str(2 * self.CHUNK) + 'B', data)\n",
    "                data_np = np.array(data_int, dtype='b')[::2] + 128\n",
    "\n",
    "                self.line.set_ydata(data_np)\n",
    "\n",
    "                # compute FFT and update line\n",
    "                yf = np.abs(fft(data_int))\n",
    "                yf_norm = 20*np.log10(yf/np.amax(yf))\n",
    "                self.line_fft.set_ydata(yf_norm[0:self.CHUNK])\n",
    "                    \n",
    "                # update figure canvas\n",
    "                self.fig.canvas.draw()\n",
    "                self.fig.canvas.flush_events()\n",
    "                frame_count += 1\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            self.fr = frame_count / (time.time() - start_time)\n",
    "            print('average frame rate = {:.0f} FPS'.format(self.fr))\n",
    "            self.exit_app()\n",
    "\n",
    "    def exit_app(self):\n",
    "        print('stream closed')\n",
    "        self.p.close(self.stream)\n",
    "\n",
    "    def onClick(self, event):\n",
    "        self.pause = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the cell below to instantiate the audio spectrum analyzer. This should pop open a window where you can view your voice in time and frequency. Try humming or whistling low, medium and high pitch notes and see what happens to the frequency spectrum!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stream started\n",
      "invalid command name \".\"\n",
      "average frame rate = 2 FPS\n",
      "stream closed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.AudioStream at 0x2d6b41f82e8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AudioStream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4**:  Try increasing self.CHUNK to smaller or larger multiples of 1024. Besides the spectrum analyzer being slower, what else do you notice, and why do you think this is happening? Don't worry if you aren't too familiar with the Discrete Fourier Transform, just provide a little intuition. (Hint: with a smaller number of data points read for the DFT, are you able to distinguish between two frequencies that are close together?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Observe a sine wave in time and frequency domains using the Arduino\n",
    "\n",
    "Before hooking up the function generator to the Arduino, always check the waveform with an oscilloscope to make sure the output is what you want.\n",
    "\n",
    "Using the same procedure as the end of lab 0: \n",
    "- Connect the function generator to the A0 and GND pins of the Arduino and upload the adc_sampling.ino sketch to the Arduino board. \n",
    "- Set the sine wave to be 50 Hz with 400mVpp and 1.5 V DC offset. \n",
    "    - **Any waveform is okay as long as none of the waveform dips below 0V or goes above 3.3V**\n",
    "- Turn on the function generator and view the serial plotter using Tools->Serial Plotter. You should see the sine wave.\n",
    "\n",
    "The Python code below is a little more in-depth tutorial on how to use \"fft\" and \"ifft\" fucntion form \"scipy.fftpack\" to do fourier transfrom and inverse fourier transform. In the given Arduino file, you already send the file to Serial after each run. Here, we import the data from Serial and do Fourier Analysis for it. After you run the Arduino file, please run the code below.\n",
    "\n",
    "**Things to check before running:**\n",
    "- Make sure the interval in the Arduino sketch is 1000 - later you can change this if you'd like\n",
    "- Make sure your waveform is okay and your equipment works\n",
    "- Make sure you know the COM (or /dev/tty if on Linux/Mac) port of your Arduino (explained in the next block)\n",
    "\n",
    "Instead of the Serial Plotter, we will now be using the Python code below to plot and analyze our signals. The code below imports the necessary Python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# allows plots to be plotted right below the cell when run\n",
    "%matplotlib inline \n",
    "import serial # the library for reading from serial com ports\n",
    "import numpy as np # naming convention for numpy library\n",
    "import matplotlib.pyplot as plt # naming convention for matplotlib\n",
    "from scipy.fftpack import fft, ifft # import discrete fourier transform and its inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding, find the serial port for your arduino. On Windows, check Device Manager and go under Ports and find the Arduino COM Port. On Macs, go to the terminal and type ls /dev/tty.\\* and look for the port corresponding to the Arduino.\n",
    "\n",
    "Also make sure to close the Serial monitor or plotter since that is accessing the serial port and only one program can access the serial port at a time.\n",
    "\n",
    "Now, run the block below to define a sampling function that samples your serial data for 3 seconds (you can edit this to to sample for any arbitrary amount of time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_arduino():\n",
    "    # preamble to set up serial communications\n",
    "    device = \"COM9\" # com port of Arduino <- CHANGE THIS TO THE ONE YOU FOUND\n",
    "    baud = 115200\n",
    "    ser = serial.Serial(device, baud, timeout=10)\n",
    "\n",
    "    # read in every line of serial code as floats and ignore corrupt data\n",
    "    def sample(size):\n",
    "        i = 0\n",
    "        data = []\n",
    "        while i < size:\n",
    "            data.append(try_float(ser.readline().decode(\"utf-8\", \"ignore\").strip('\\n').strip('\\r')))\n",
    "            i += 1\n",
    "        return data\n",
    "    def try_float(s):\n",
    "        try:\n",
    "            return float(s)\n",
    "        except:\n",
    "            return 0\n",
    "    raw_data = sample(3000) # <- Adjust this line to read in more/less data\n",
    "    ser.close()\n",
    "    return raw_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following block of code to sample and plot your waveform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "signal = sample_arduino()\n",
    "plt.plot(signal[100:200]) # change the indices to zoom in/out in time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To take a fourier transform of the above signal and analyze its frequency spectrum, run the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dft = fft(signal) # calculate fourier transform\n",
    "fs = 1000 # sampling rate\n",
    "N = len(dft) # length of discrete fourier transform\n",
    "freqs = [i*fs/N for i in range(N)] # convert from dft frequencies to Hz\n",
    "plt.plot(freqs[2:1000], np.abs(dft[2:1000])) # change the indices to zoom in/out in frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you're able to sample a chunk of data from the Arduino's analog inputs at a time and process it. This is cool, but we can do better! Similar to the Audio Spectrum Analyzer, let's view the spectrum of the Arduino's analog input in real time. Run the cell below to run a script that will generate a spectrum analyzer for the Arduino. Leave it running as you do Question 5 and 6. \n",
    "\n",
    "#### Before running the cell, open up the python file in a text editor of your choice and change the \"device = \" line to include the correct COM or /dev/ port of your Arduino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COM11\n"
     ]
    },
    {
     "ename": "SerialException",
     "evalue": "could not open port 'COM11': FileNotFoundError(2, 'The system cannot find the file specified.', None, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSerialException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Quincy\\Documents\\School-Stuff\\Spring 2018\\BIOE 101 TA\\bioe101-sp18\\Lab 1\\serial_spectrumQT.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[0mbaud\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m115200\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0mcomms\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m     \u001b[0mcomms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mserial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbaud\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0maudio_app\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAudioStream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\serial\\serialwin32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_overlapped_read\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_overlapped_write\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSerial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\serial\\serialutil.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, port, baudrate, bytesize, parity, stopbits, timeout, xonxoff, rtscts, write_timeout, dsrdtr, inter_byte_timeout, exclusive, **kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mport\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;31m#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\serial\\serialwin32.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_port_handle\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mwin32\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINVALID_HANDLE_VALUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_port_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m    \u001b[1;31m# 'cause __del__ is called anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mSerialException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"could not open port {!r}: {!r}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mportstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWinError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSerialException\u001b[0m: could not open port 'COM11': FileNotFoundError(2, 'The system cannot find the file specified.', None, 2)"
     ]
    }
   ],
   "source": [
    "%matplotlib tk\n",
    "%run serial_spectrumQT.py COM11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5**: Similar to Part 1, we'll try increasing frequencies until some weird things happen. Now increase the frequency of the function generator (suggestion: step 50 Hz at a time starting at 50 Hz). At what point does the frequency not match your input? \n",
    "\n",
    "**Question 6**: What property of LTI systems does this violate? In general, why is sampling not an LTI operator?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Voice Recognition ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your convenience if you want to just do this section, run the cell below to import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyaudio\n",
    "import struct\n",
    "from scipy.fftpack import fft\n",
    "import sys\n",
    "import time\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this section, you will develop an algorithm to distinguish between your and your partner's voices using Python and your computer's microphone.\n",
    "\n",
    "While speaking into the microphone, make sure to be loud and clear. Try things like saying a specific word or humming/whistling a note!\n",
    "\n",
    "Run the cell below to define a function that will be used to record your voice and plot and return your voice data in time and frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def record_voice():\n",
    "    CHUNK = 1024 * 10\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 1\n",
    "    RATE = 4000\n",
    "    pause = False\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(\n",
    "        format=FORMAT,\n",
    "        channels=CHANNELS,\n",
    "        rate=RATE,\n",
    "        input=True,\n",
    "        output=True,\n",
    "        frames_per_buffer=CHUNK,\n",
    "    )\n",
    "    # x variables for plotting\n",
    "    x = np.arange(0, 2 * CHUNK, 2)\n",
    "    xf = np.linspace(0, RATE//2, CHUNK)\n",
    "\n",
    "    # create matplotlib figure and axes\n",
    "    fig, (ax1, ax2) = plt.subplots(2, figsize=(15, 7))\n",
    "\n",
    "    # create a line object with random data\n",
    "    line, = ax1.plot(x, np.random.rand(CHUNK), '-', lw=2)\n",
    "\n",
    "    # create line for spectrum\n",
    "    line_fft, = ax2.plot(\n",
    "        xf, np.random.rand(CHUNK), '-', lw=2)\n",
    "\n",
    "    # format waveform axes\n",
    "    ax1.set_title('AUDIO WAVEFORM')\n",
    "    ax1.set_xlabel('samples')\n",
    "    ax1.set_ylabel('volume')\n",
    "    ax1.set_ylim(-50, 300)\n",
    "    ax1.set_xlim(0, 2 * CHUNK)\n",
    "    plt.setp(\n",
    "        ax1, yticks=[0, 128, 255],\n",
    "        xticks=[0, CHUNK, 2 * CHUNK],\n",
    "    )\n",
    "    plt.setp(ax2, yticks=[-100, -50, 0],)\n",
    "\n",
    "    # format spectrum axes\n",
    "    ax2.set_xlim(20, 2000)\n",
    "    ax2.set_ylim(-100, 0) # adjust this line if your signal is clipped off in the fourier domain\n",
    "    data = stream.read(CHUNK, exception_on_overflow=False)\n",
    "    data_int = struct.unpack(str(2 * CHUNK) + 'B', data)\n",
    "    data_np = np.array(data_int, dtype='b')[::2] + 128\n",
    "    line.set_ydata(data_np)\n",
    "\n",
    "    # compute FFT and update line\n",
    "    yf = np.abs(fft(data_int))\n",
    "    yf_norm = 20*np.log10(yf/np.amax(yf))\n",
    "    line_fft.set_ydata(yf_norm[0:CHUNK])\n",
    "    data_ft = np.abs(yf[0:CHUNK])\n",
    "    \n",
    "    return np.array(data_int), data_ft[1:RATE//2]/CHUNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.         -40.77342336 -50.42421932 ..., -49.65504085 -50.42421932\n",
      " -40.77342336]\n",
      "Partner 1\n"
     ]
    }
   ],
   "source": [
    "voice1 = record_voice()\n",
    "print(\"Partner 1\")\n",
    "# SAVE PARTNER 1 DATA #\n",
    "partner_1_data, partner_1_ft = voice1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voice2 = record_voice()\n",
    "print(\"Partner 2\")\n",
    "# SAVE PARTNER 2 DATA #\n",
    "partner_2_data, partner_2_ft = voice2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voice3 = record_voice()\n",
    "print(\"Partner 3\")\n",
    "# SAVE PARTNER 3 DATA #\n",
    "partner_3_data, partner_3_ft = voice3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Question 7**: How clean are the voice samples? What kinds of noises/interferences may be present?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Questions\n",
    "- attempting one will give you partial bonus points, attempting both will give more partial bonus points\n",
    "- successfully implementing one or both will net you half or full bonus points respectively - successful implementation will be defined as a working code that runs and does what it's meant to do, but not necessarily be accurate in something like detecting whose voice it is.\n",
    "- attach your code to your lab report if you've attempted the bonus for some credit and get checked off by a GSI if you think you've successfully implemented the bonus for full credit\n",
    "\n",
    "**Bonus Question 1**: Now that you've stored all of your group members' voices, create a program that takes in a voice sample and outputs the person whose voice matches it the most. (Hint: there's an algorithm called cross-correlation that calculates the similarity between two signals. You can use np.correlate(partner_1_ft, partner_2_ft) to compare two voices)\n",
    "\n",
    "**Bonus Question 2**: You might have noticed that your signal was a little noisy. Create a program that digitally filters out that noise (you get to choose your cutoff frequencies). (Hint: try using a digital filter from the scipy library like the one here https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.signal.lfilter.html)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
